{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow-object-detection-training-colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQCnYPVDrsgx",
        "colab_type": "text"
      },
      "source": [
        "# [How to train an object detection model easy for free](https://www.dlology.com/blog/how-to-train-an-object-detection-model-easy-for-free/) | DLology Blog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhzxsJb3dpWq",
        "colab_type": "text"
      },
      "source": [
        "## Configs and Hyperparameters\n",
        "\n",
        "Support a variety of models, you can find more pretrained model from [Tensorflow detection model zoo: COCO-trained models](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models), as well as their pipline config files in [object_detection/samples/configs/](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnNXNQCjdniL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "8727f150-4d0f-4302-eae4-c4730305a845"
      },
      "source": [
        "%tensorflow_version 1.15.2\n",
        "# If you forked the repository, you can replace the link.\n",
        "repo_url = 'https://github.com/edmirh/boardDetection'\n",
        "\n",
        "# Number of training steps.\n",
        "num_steps = 10000  # 200000\n",
        "\n",
        "# Number of evaluation steps.\n",
        "num_eval_steps = 50\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "        'batch_size': 8\n",
        "    }\n",
        "}\n",
        "\n",
        "# Pick the model you want to use\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "selected_model = 'ssd_mobilenet_v2'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.15.2`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4V-XE6kbkc1",
        "colab_type": "text"
      },
      "source": [
        "## Clone the `object_detection_demo` repository or your fork."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxc3DmvLQF3z",
        "colab_type": "code",
        "outputId": "f1acde51-be20-4c0e-a7db-aa93c002c1a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "fatal: destination path 'boardDetection' already exists and is not an empty directory.\n",
            "/content/boardDetection\n",
            "remote: Enumerating objects: 137, done.\u001b[K\n",
            "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 132 (delta 64), reused 132 (delta 64), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (132/132), 4.68 MiB | 7.72 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), completed with 1 local object.\n",
            "From https://github.com/edmirh/boardDetection\n",
            "   9b6845a..83e2a8f  master     -> origin/master\n",
            "Updating 9b6845a..83e2a8f\n",
            "Fast-forward\n",
            " ...ESP32 Development Board WiFi+Bluetooth-1000x750.jpg | Bin \u001b[31m102553\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " .../STM32F407-Discovery-Kit-for-STM32F407Robu-3.jpg    | Bin \u001b[31m75293\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " ...-with-STM32F407-STM32F4-Discovery-supports-mbed.jpg | Bin \u001b[31m92011\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " ...-m4-Development-Board-Module-st-link-V2.jpg_q50.jpg | Bin \u001b[31m106583\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/test/Untitled-1.jpg                        | Bin \u001b[31m439020\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/test/W5500-Ethernet-1.jpg                  | Bin \u001b[31m235406\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " ...IP-51-STM32-microcontroller-program-over-W5100.jpeg | Bin \u001b[31m58898\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " .../test/e47842a1-c853-420f-919f-43153bedaf13.jpg      | Bin \u001b[31m0\u001b[m -> \u001b[32m219608\u001b[m bytes\n",
            " .../test/e47842a1-c853-420f-919f-43153bedaf13.xml      |   1 \u001b[32m+\u001b[m\n",
            " .../test/e6e834f3-230c-439d-a0e5-58d7dce5d32d.jpg      | Bin \u001b[31m0\u001b[m -> \u001b[32m11471\u001b[m bytes\n",
            " .../test/e6e834f3-230c-439d-a0e5-58d7dce5d32d.xml      |   1 \u001b[32m+\u001b[m\n",
            " .../test/e785c99b-ce85-498e-bf4f-3b6e47c271fa.jpg      | Bin \u001b[31m0\u001b[m -> \u001b[32m105411\u001b[m bytes\n",
            " .../test/e785c99b-ce85-498e-bf4f-3b6e47c271fa.xml      |   1 \u001b[32m+\u001b[m\n",
            " .../test/eab18093-680f-4699-8a0b-6d0ceed28a1c.jpg      | Bin \u001b[31m0\u001b[m -> \u001b[32m12343\u001b[m bytes\n",
            " .../test/eab18093-680f-4699-8a0b-6d0ceed28a1c.xml      |   1 \u001b[32m+\u001b[m\n",
            " .../test/eb710f26-75b0-43ed-a44f-85a0726eca29.jpg      | Bin \u001b[31m0\u001b[m -> \u001b[32m145836\u001b[m bytes\n",
            " .../test/eb710f26-75b0-43ed-a44f-85a0726eca29.xml      |   1 \u001b[32m+\u001b[m\n",
            " .../test/f18d1539-e835-4374-8ba7-71765dc57e4d.jpg      | Bin \u001b[31m0\u001b[m -> \u001b[32m12249\u001b[m bytes\n",
            " .../test/f18d1539-e835-4374-8ba7-71765dc57e4d.xml      |   1 \u001b[32m+\u001b[m\n",
            " .../test/f6188b6a-5e8b-4438-916f-0eca0d4bfdb0.jpg      | Bin \u001b[31m0\u001b[m -> \u001b[32m40291\u001b[m bytes\n",
            " .../test/f6188b6a-5e8b-4438-916f-0eca0d4bfdb0.xml      |   1 \u001b[32m+\u001b[m\n",
            " .../test/f9521cc2-5e2b-4a50-a0ba-2eb2ec97f3ff.jpg      | Bin \u001b[31m0\u001b[m -> \u001b[32m66829\u001b[m bytes\n",
            " .../test/f9521cc2-5e2b-4a50-a0ba-2eb2ec97f3ff.xml      |   1 \u001b[32m+\u001b[m\n",
            " .../test/fe313cd5-7f9e-4b9e-a7e1-98ac05958aa3.jpg      | Bin \u001b[31m0\u001b[m -> \u001b[32m32450\u001b[m bytes\n",
            " .../test/fe313cd5-7f9e-4b9e-a7e1-98ac05958aa3.xml      |   1 \u001b[32m+\u001b[m\n",
            " .../test/fe863c42-ad29-4c46-ab14-6f6f48d349d6.jpg      | Bin \u001b[31m0\u001b[m -> \u001b[32m164316\u001b[m bytes\n",
            " .../test/fe863c42-ad29-4c46-ab14-6f6f48d349d6.xml      |   1 \u001b[32m+\u001b[m\n",
            " .../test/ffead925-fa02-4cbd-b851-98b99cf0bf03.jpg      | Bin \u001b[31m0\u001b[m -> \u001b[32m71817\u001b[m bytes\n",
            " .../test/ffead925-fa02-4cbd-b851-98b99cf0bf03.xml      |   1 \u001b[32m+\u001b[m\n",
            " data/images/test/images (1).jpg                        | Bin \u001b[31m8259\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/test/images (3).jpg                        | Bin \u001b[31m8169\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/test/images (5).jpg                        | Bin \u001b[31m6761\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/test/images (6).jpg                        | Bin \u001b[31m7691\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/test/images.jpg                            | Bin \u001b[31m8060\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " ...lemci-kitleri-stmicroelectronics-14397-39-O (1).jpg | Bin \u001b[31m33441\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " ...1-islemci-kitleri-stmicroelectronics-14397-39-O.jpg | Bin \u001b[31m33441\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " ...kit-diger-kartlar-st-stm32f407g-disc1-9286-34-B.jpg | Bin \u001b[31m100673\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/test/stm32f4_discovery_large.jpg           | Bin \u001b[31m266475\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/test/stm32f4_discovery_small.jpg           | Bin \u001b[31m87782\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/test/w5500-500x500.v2.jpg                  | Bin \u001b[31m45521\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " .../train/03ff26f3-394f-4f85-9aee-1d382178ef58.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m171864\u001b[m bytes\n",
            " .../train/03ff26f3-394f-4f85-9aee-1d382178ef58.xml     |   1 \u001b[32m+\u001b[m\n",
            " data/images/train/06aa144e8d.jpg                       | Bin \u001b[31m133683\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " .../train/0b23a5f7-4ed0-492b-ab17-0da570e3cf00.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m47240\u001b[m bytes\n",
            " .../train/0b23a5f7-4ed0-492b-ab17-0da570e3cf00.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/102b6007-fe30-4f2c-af99-5c98cfc77f00.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m127344\u001b[m bytes\n",
            " .../train/102b6007-fe30-4f2c-af99-5c98cfc77f00.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/126e64bb-a7d4-4a45-9165-2a5ac7c5e2c8.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m92164\u001b[m bytes\n",
            " .../train/126e64bb-a7d4-4a45-9165-2a5ac7c5e2c8.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/1326d3c6-5465-4dd3-9a26-cb8c65931f1a.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m34912\u001b[m bytes\n",
            " .../train/1326d3c6-5465-4dd3-9a26-cb8c65931f1a.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/17748e6c-e8ba-4111-b227-8314ce0f02e6.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m227035\u001b[m bytes\n",
            " .../train/17748e6c-e8ba-4111-b227-8314ce0f02e6.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/1ff17ac2-a8b5-4975-a264-976f4b494969.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m117729\u001b[m bytes\n",
            " .../train/1ff17ac2-a8b5-4975-a264-976f4b494969.xml     |   1 \u001b[32m+\u001b[m\n",
            " data/images/train/20200510_163916.jpg                  | Bin \u001b[31m575981\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/20200510_163923.jpg                  | Bin \u001b[31m390149\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/20200510_163930.jpg                  | Bin \u001b[31m482520\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/20200510_163933.jpg                  | Bin \u001b[31m572702\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/20200510_163937.jpg                  | Bin \u001b[31m359148\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/20200510_163944.jpg                  | Bin \u001b[31m425469\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/20200510_164138.jpg                  | Bin \u001b[31m357584\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/20200510_164140.jpg                  | Bin \u001b[31m389424\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/20200510_164146.jpg                  | Bin \u001b[31m368085\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/20200510_164151.jpg                  | Bin \u001b[31m335819\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/20200510_164156.jpg                  | Bin \u001b[31m305830\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/20200510_164201.jpg                  | Bin \u001b[31m312276\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/20200510_164207.jpg                  | Bin \u001b[31m275460\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/20200510_164212.jpg                  | Bin \u001b[31m292379\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/20200510_164217.jpg                  | Bin \u001b[31m329384\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/20200510_164224.jpg                  | Bin \u001b[31m376465\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/20200510_164226.jpg                  | Bin \u001b[31m351679\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/20200510_164230.jpg                  | Bin \u001b[31m352571\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/20200510_164235.jpg                  | Bin \u001b[31m336912\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/20200510_164238.jpg                  | Bin \u001b[31m339606\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/20200510_164243.jpg                  | Bin \u001b[31m297763\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/20200510_164247.jpg                  | Bin \u001b[31m311761\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/20200510_164251.jpg                  | Bin \u001b[31m309534\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/20200510_164255.jpg                  | Bin \u001b[31m368229\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/210941-2.jpg                         | Bin \u001b[31m159693\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " .../train/24144448-f99a-4cb0-8bcb-48cbc67da8e4.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m34420\u001b[m bytes\n",
            " .../train/24144448-f99a-4cb0-8bcb-48cbc67da8e4.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/26b61ac3-2428-4257-a70c-9d4b9b15de23.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m129936\u001b[m bytes\n",
            " .../train/26b61ac3-2428-4257-a70c-9d4b9b15de23.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/28989899-ed22-4abc-96ec-ffae09f98145.jpg     | Bin \u001b[31m181082\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " .../train/2fae3ab1-bf29-4ebe-8f09-9a7c854533dc.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m17545\u001b[m bytes\n",
            " .../train/2fae3ab1-bf29-4ebe-8f09-9a7c854533dc.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/4000652f-3991-4c12-af67-48afb050a541.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m49003\u001b[m bytes\n",
            " .../train/4000652f-3991-4c12-af67-48afb050a541.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/4068c54e-40c7-4489-840e-855f8d4cce46.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m94561\u001b[m bytes\n",
            " .../train/4068c54e-40c7-4489-840e-855f8d4cce46.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/43f766ca-5bc8-4f63-84dd-ce5ea67864ab.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m11856\u001b[m bytes\n",
            " .../train/43f766ca-5bc8-4f63-84dd-ce5ea67864ab.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/44d2f03a-56c6-4ca6-ad48-fcb208621a7f.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m104691\u001b[m bytes\n",
            " .../train/44d2f03a-56c6-4ca6-ad48-fcb208621a7f.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/4749d94a-2845-44e3-8975-443a52c99640.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m105961\u001b[m bytes\n",
            " .../train/4749d94a-2845-44e3-8975-443a52c99640.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/4794325c-758a-45e4-bcee-3196acbde876.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m221529\u001b[m bytes\n",
            " .../train/4794325c-758a-45e4-bcee-3196acbde876.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/4aa5bd90-ad56-4dfa-9088-7bd635d030b6.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m64749\u001b[m bytes\n",
            " .../train/4aa5bd90-ad56-4dfa-9088-7bd635d030b6.xml     |   1 \u001b[32m+\u001b[m\n",
            " data/images/train/51lc7DrLgpL._SX425_.jpg              | Bin \u001b[31m26199\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/51p33bRuisL._SX342_.jpg              | Bin \u001b[31m20338\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " .../train/59ea66f8-a93f-4d4d-a43f-79a6f54c4e78.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m78754\u001b[m bytes\n",
            " .../train/59ea66f8-a93f-4d4d-a43f-79a6f54c4e78.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/5aeb717f-2d95-4b06-8062-7c7fd81f4d54.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m102238\u001b[m bytes\n",
            " .../train/5aeb717f-2d95-4b06-8062-7c7fd81f4d54.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/60c52a0a-c574-44ac-91f1-bd89760e8663.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m17545\u001b[m bytes\n",
            " .../train/60c52a0a-c574-44ac-91f1-bd89760e8663.xml     |   1 \u001b[32m+\u001b[m\n",
            " data/images/train/61CkxMiIzsL._AC_SX355_.jpg           | Bin \u001b[31m16871\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " .../train/622227d2-a8ac-49e7-acf5-50b6e5ed369f.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m28044\u001b[m bytes\n",
            " .../train/622227d2-a8ac-49e7-acf5-50b6e5ed369f.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/62a085f6-8759-4cef-abe5-f5dc417242ba.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m72307\u001b[m bytes\n",
            " .../train/62a085f6-8759-4cef-abe5-f5dc417242ba.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/6949c2d0-9af4-4a54-bd54-1b6bb3dfa778.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m82825\u001b[m bytes\n",
            " .../train/6949c2d0-9af4-4a54-bd54-1b6bb3dfa778.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/714af586-2fe1-4b2a-9f92-bf44d0e5b31c.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m89044\u001b[m bytes\n",
            " .../train/714af586-2fe1-4b2a-9f92-bf44d0e5b31c.xml     |   1 \u001b[32m+\u001b[m\n",
            " data/images/train/71cy2TFQu8L._SL1500_.jpg             | Bin \u001b[31m161791\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/71cy2TFQu8L._SX355_.jpg              | Bin \u001b[31m11987\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " .../train/749102b4-aa6f-458a-8a7d-5104f016f8ed.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m113791\u001b[m bytes\n",
            " .../train/749102b4-aa6f-458a-8a7d-5104f016f8ed.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/776d7ee0-8e8f-4415-8eb2-bc0451c9b089.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m51930\u001b[m bytes\n",
            " .../train/776d7ee0-8e8f-4415-8eb2-bc0451c9b089.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/78babe87-7d87-4c13-9eec-aab373c6cddb.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m110122\u001b[m bytes\n",
            " .../train/78babe87-7d87-4c13-9eec-aab373c6cddb.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/79737503-7db5-4268-a8d7-fb80f42a68bc.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m34420\u001b[m bytes\n",
            " .../train/79737503-7db5-4268-a8d7-fb80f42a68bc.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/797a80c9-5154-468b-9ccf-90c8170290f9.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m95351\u001b[m bytes\n",
            " .../train/797a80c9-5154-468b-9ccf-90c8170290f9.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/8af14c37-64e0-452c-9432-6ccca33c33d0.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m105461\u001b[m bytes\n",
            " .../train/8af14c37-64e0-452c-9432-6ccca33c33d0.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/92b0d01b-6974-4924-a6ab-aa93c46cd60b.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m58059\u001b[m bytes\n",
            " .../train/92b0d01b-6974-4924-a6ab-aa93c46cd60b.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/9684f1f5-0fe8-4201-bcde-f602b68b6cf9.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m28524\u001b[m bytes\n",
            " .../train/9684f1f5-0fe8-4201-bcde-f602b68b6cf9.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/9aacb3ab-2bd8-42cb-aa3b-bd97dfb58908.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m146506\u001b[m bytes\n",
            " .../train/9aacb3ab-2bd8-42cb-aa3b-bd97dfb58908.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/9b0d2111-d33b-4ea7-a04b-b5aad7dab217.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m164891\u001b[m bytes\n",
            " .../train/9b0d2111-d33b-4ea7-a04b-b5aad7dab217.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/9b869b93-7d34-45a1-aa90-38461b44faa6.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m9215\u001b[m bytes\n",
            " .../train/9b869b93-7d34-45a1-aa90-38461b44faa6.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/9eaf56b7-3f0e-4786-a61c-cf112ca7d509.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m23658\u001b[m bytes\n",
            " .../train/9eaf56b7-3f0e-4786-a61c-cf112ca7d509.xml     |   1 \u001b[32m+\u001b[m\n",
            " data/images/train/A9BU_1_201911181371207187.jpg        | Bin \u001b[31m35925\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/ARD__821_1188.jpg                    | Bin \u001b[31m56911\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " .../images/train/DISC1-Stm32f407__11873.1561068028.jpg | Bin \u001b[31m138334\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " ...ESP32 Development Board WiFi+Bluetooth-1000x750.jpg | Bin \u001b[31m102553\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " ...Networking-Smart-Component-Esp-Wroom-32-Esp-32s.jpg | Bin \u001b[31m30682\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/HTB1Zruyee38SeJjSZFPq6A_vFXat.jpg    | Bin \u001b[31m59893\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " .../train/a53d02ce-1ca2-4685-ae8a-9603f8e3f23b.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m11106\u001b[m bytes\n",
            " .../train/a53d02ce-1ca2-4685-ae8a-9603f8e3f23b.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/a65bbcd1-8633-47e7-8e7c-ea40ca726dae.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m79856\u001b[m bytes\n",
            " .../train/a65bbcd1-8633-47e7-8e7c-ea40ca726dae.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/b169896b-c7e0-4487-8c17-05f5007054e9.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m207186\u001b[m bytes\n",
            " .../train/b169896b-c7e0-4487-8c17-05f5007054e9.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/b1f2763d-f5f2-420e-a1f4-11d4dc4d688f.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m102391\u001b[m bytes\n",
            " .../train/b1f2763d-f5f2-420e-a1f4-11d4dc4d688f.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/b25b4382-9fcc-41dc-a9ff-de053ccd4e26.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m72956\u001b[m bytes\n",
            " .../train/b25b4382-9fcc-41dc-a9ff-de053ccd4e26.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/b7ce7b11-3424-47d8-bd04-ef6600ce120b.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m79084\u001b[m bytes\n",
            " .../train/b7ce7b11-3424-47d8-bd04-ef6600ce120b.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/bea65fe4-2cfc-41fd-8a34-8a7fa746ee47.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m40291\u001b[m bytes\n",
            " .../train/bea65fe4-2cfc-41fd-8a34-8a7fa746ee47.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/bf8ad973-9984-4c18-92e0-934da85f8c0b.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m10318\u001b[m bytes\n",
            " .../train/bf8ad973-9984-4c18-92e0-934da85f8c0b.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/c464c486-1627-4759-a52d-0aeb988c2549.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m13863\u001b[m bytes\n",
            " .../train/c464c486-1627-4759-a52d-0aeb988c2549.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/c47e9ad0-a5e8-45dc-884d-3da883921a09.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m11901\u001b[m bytes\n",
            " .../train/c47e9ad0-a5e8-45dc-884d-3da883921a09.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/c5428add-9901-4102-b3f1-7c701cc6ddb3.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m63809\u001b[m bytes\n",
            " .../train/c5428add-9901-4102-b3f1-7c701cc6ddb3.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/c5bfdf9a-1e62-4fa8-965b-7a8cef000fdc.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m131473\u001b[m bytes\n",
            " .../train/c5bfdf9a-1e62-4fa8-965b-7a8cef000fdc.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/c68c5c53-eff8-41ad-b6f5-204351464e7c.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m68839\u001b[m bytes\n",
            " .../train/c68c5c53-eff8-41ad-b6f5-204351464e7c.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/d281a945-5eab-4630-ae5f-8bd2a0d01d22.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m16352\u001b[m bytes\n",
            " .../train/d281a945-5eab-4630-ae5f-8bd2a0d01d22.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/d4d6cd28-627b-434c-a0d2-ec983646434a.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m87397\u001b[m bytes\n",
            " .../train/d4d6cd28-627b-434c-a0d2-ec983646434a.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/d9edf430-7346-4dda-b274-e9ddcbeaa610.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m32450\u001b[m bytes\n",
            " .../train/d9edf430-7346-4dda-b274-e9ddcbeaa610.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/da24a855-6709-4096-932f-7c82f85b2219.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m37678\u001b[m bytes\n",
            " .../train/da24a855-6709-4096-932f-7c82f85b2219.xml     |   1 \u001b[32m+\u001b[m\n",
            " .../train/dcbf1497-2d27-45ef-8705-ad476ce06bad.jpg     | Bin \u001b[31m0\u001b[m -> \u001b[32m96383\u001b[m bytes\n",
            " .../train/dcbf1497-2d27-45ef-8705-ad476ce06bad.xml     |   1 \u001b[32m+\u001b[m\n",
            " data/images/train/download (1).jpg                     | Bin \u001b[31m11631\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/download (2).jpg                     | Bin \u001b[31m8072\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/download (3).jpg                     | Bin \u001b[31m6486\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/download (4).jpg                     | Bin \u001b[31m7873\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/download.jpg                         | Bin \u001b[31m9670\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " ...oard-wifi-bluetooth-ultra-low-power-500x500 (1).png | Bin \u001b[31m235315\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " ...nt-board-wifi-bluetooth-ultra-low-power-500x500.png | Bin \u001b[31m235315\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " .../esp32-wroom-development-board-wifibluetooth.jpg    | Bin \u001b[31m31264\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/esp8266-esp-32-wroom-32.jpg          | Bin \u001b[31m90148\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/images (2).jpg                       | Bin \u001b[31m6957\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/images (3).jpg                       | Bin \u001b[31m8169\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/images (4).jpg                       | Bin \u001b[31m11631\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/images (5).jpg                       | Bin \u001b[31m6761\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/images (6).jpg                       | Bin \u001b[31m7691\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/images.jpg                           | Bin \u001b[31m8060\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/mod-w5500_n.jpg                      | Bin \u001b[31m128821\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " ...kit-diger-kartlar-st-stm32f407g-disc1-9286-34-B.jpg | Bin \u001b[31m100673\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " data/images/train/stm32f4.jpg                          | Bin \u001b[31m120669\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " 204 files changed, 65 insertions(+)\n",
            " delete mode 100644 data/images/test/ESP32 Development Board WiFi+Bluetooth-1000x750.jpg\n",
            " delete mode 100644 data/images/test/STM32F407-Discovery-Kit-for-STM32F407Robu-3.jpg\n",
            " delete mode 100644 data/images/test/STM32F407G-DISC1-new-STM32F4DISCOVERY-Board-for-STM32F4-series-with-STM32F407-STM32F4-Discovery-supports-mbed.jpg\n",
            " delete mode 100644 data/images/test/Stm32f4-Discovery-Stm32f407-Cortex-m4-Development-Board-Module-st-link-V2.jpg_q50.jpg\n",
            " delete mode 100644 data/images/test/Untitled-1.jpg\n",
            " delete mode 100644 data/images/test/W5500-Ethernet-1.jpg\n",
            " delete mode 100644 data/images/test/W5500-Ethernet-network-module-hardware-TCP-IP-51-STM32-microcontroller-program-over-W5100.jpeg\n",
            " create mode 100644 data/images/test/e47842a1-c853-420f-919f-43153bedaf13.jpg\n",
            " create mode 100644 data/images/test/e47842a1-c853-420f-919f-43153bedaf13.xml\n",
            " create mode 100644 data/images/test/e6e834f3-230c-439d-a0e5-58d7dce5d32d.jpg\n",
            " create mode 100644 data/images/test/e6e834f3-230c-439d-a0e5-58d7dce5d32d.xml\n",
            " create mode 100644 data/images/test/e785c99b-ce85-498e-bf4f-3b6e47c271fa.jpg\n",
            " create mode 100644 data/images/test/e785c99b-ce85-498e-bf4f-3b6e47c271fa.xml\n",
            " create mode 100644 data/images/test/eab18093-680f-4699-8a0b-6d0ceed28a1c.jpg\n",
            " create mode 100644 data/images/test/eab18093-680f-4699-8a0b-6d0ceed28a1c.xml\n",
            " create mode 100644 data/images/test/eb710f26-75b0-43ed-a44f-85a0726eca29.jpg\n",
            " create mode 100644 data/images/test/eb710f26-75b0-43ed-a44f-85a0726eca29.xml\n",
            " create mode 100644 data/images/test/f18d1539-e835-4374-8ba7-71765dc57e4d.jpg\n",
            " create mode 100644 data/images/test/f18d1539-e835-4374-8ba7-71765dc57e4d.xml\n",
            " create mode 100644 data/images/test/f6188b6a-5e8b-4438-916f-0eca0d4bfdb0.jpg\n",
            " create mode 100644 data/images/test/f6188b6a-5e8b-4438-916f-0eca0d4bfdb0.xml\n",
            " create mode 100644 data/images/test/f9521cc2-5e2b-4a50-a0ba-2eb2ec97f3ff.jpg\n",
            " create mode 100644 data/images/test/f9521cc2-5e2b-4a50-a0ba-2eb2ec97f3ff.xml\n",
            " create mode 100644 data/images/test/fe313cd5-7f9e-4b9e-a7e1-98ac05958aa3.jpg\n",
            " create mode 100644 data/images/test/fe313cd5-7f9e-4b9e-a7e1-98ac05958aa3.xml\n",
            " create mode 100644 data/images/test/fe863c42-ad29-4c46-ab14-6f6f48d349d6.jpg\n",
            " create mode 100644 data/images/test/fe863c42-ad29-4c46-ab14-6f6f48d349d6.xml\n",
            " create mode 100644 data/images/test/ffead925-fa02-4cbd-b851-98b99cf0bf03.jpg\n",
            " create mode 100644 data/images/test/ffead925-fa02-4cbd-b851-98b99cf0bf03.xml\n",
            " delete mode 100644 data/images/test/images (1).jpg\n",
            " delete mode 100644 data/images/test/images (3).jpg\n",
            " delete mode 100644 data/images/test/images (5).jpg\n",
            " delete mode 100644 data/images/test/images (6).jpg\n",
            " delete mode 100644 data/images/test/images.jpg\n",
            " delete mode 100644 data/images/test/stm32-islemci-kiti-stm32f407g-disc1-islemci-kitleri-stmicroelectronics-14397-39-O (1).jpg\n",
            " delete mode 100644 data/images/test/stm32-islemci-kiti-stm32f407g-disc1-islemci-kitleri-stmicroelectronics-14397-39-O.jpg\n",
            " delete mode 100644 data/images/test/stm32f4-discovery-kit-diger-kartlar-st-stm32f407g-disc1-9286-34-B.jpg\n",
            " delete mode 100644 data/images/test/stm32f4_discovery_large.jpg\n",
            " delete mode 100644 data/images/test/stm32f4_discovery_small.jpg\n",
            " delete mode 100644 data/images/test/w5500-500x500.v2.jpg\n",
            " create mode 100644 data/images/train/03ff26f3-394f-4f85-9aee-1d382178ef58.jpg\n",
            " create mode 100644 data/images/train/03ff26f3-394f-4f85-9aee-1d382178ef58.xml\n",
            " delete mode 100644 data/images/train/06aa144e8d.jpg\n",
            " create mode 100644 data/images/train/0b23a5f7-4ed0-492b-ab17-0da570e3cf00.jpg\n",
            " create mode 100644 data/images/train/0b23a5f7-4ed0-492b-ab17-0da570e3cf00.xml\n",
            " create mode 100644 data/images/train/102b6007-fe30-4f2c-af99-5c98cfc77f00.jpg\n",
            " create mode 100644 data/images/train/102b6007-fe30-4f2c-af99-5c98cfc77f00.xml\n",
            " create mode 100644 data/images/train/126e64bb-a7d4-4a45-9165-2a5ac7c5e2c8.jpg\n",
            " create mode 100644 data/images/train/126e64bb-a7d4-4a45-9165-2a5ac7c5e2c8.xml\n",
            " create mode 100644 data/images/train/1326d3c6-5465-4dd3-9a26-cb8c65931f1a.jpg\n",
            " create mode 100644 data/images/train/1326d3c6-5465-4dd3-9a26-cb8c65931f1a.xml\n",
            " create mode 100644 data/images/train/17748e6c-e8ba-4111-b227-8314ce0f02e6.jpg\n",
            " create mode 100644 data/images/train/17748e6c-e8ba-4111-b227-8314ce0f02e6.xml\n",
            " create mode 100644 data/images/train/1ff17ac2-a8b5-4975-a264-976f4b494969.jpg\n",
            " create mode 100644 data/images/train/1ff17ac2-a8b5-4975-a264-976f4b494969.xml\n",
            " delete mode 100644 data/images/train/20200510_163916.jpg\n",
            " delete mode 100644 data/images/train/20200510_163923.jpg\n",
            " delete mode 100644 data/images/train/20200510_163930.jpg\n",
            " delete mode 100644 data/images/train/20200510_163933.jpg\n",
            " delete mode 100644 data/images/train/20200510_163937.jpg\n",
            " delete mode 100644 data/images/train/20200510_163944.jpg\n",
            " delete mode 100644 data/images/train/20200510_164138.jpg\n",
            " delete mode 100644 data/images/train/20200510_164140.jpg\n",
            " delete mode 100644 data/images/train/20200510_164146.jpg\n",
            " delete mode 100644 data/images/train/20200510_164151.jpg\n",
            " delete mode 100644 data/images/train/20200510_164156.jpg\n",
            " delete mode 100644 data/images/train/20200510_164201.jpg\n",
            " delete mode 100644 data/images/train/20200510_164207.jpg\n",
            " delete mode 100644 data/images/train/20200510_164212.jpg\n",
            " delete mode 100644 data/images/train/20200510_164217.jpg\n",
            " delete mode 100644 data/images/train/20200510_164224.jpg\n",
            " delete mode 100644 data/images/train/20200510_164226.jpg\n",
            " delete mode 100644 data/images/train/20200510_164230.jpg\n",
            " delete mode 100644 data/images/train/20200510_164235.jpg\n",
            " delete mode 100644 data/images/train/20200510_164238.jpg\n",
            " delete mode 100644 data/images/train/20200510_164243.jpg\n",
            " delete mode 100644 data/images/train/20200510_164247.jpg\n",
            " delete mode 100644 data/images/train/20200510_164251.jpg\n",
            " delete mode 100644 data/images/train/20200510_164255.jpg\n",
            " delete mode 100644 data/images/train/210941-2.jpg\n",
            " create mode 100644 data/images/train/24144448-f99a-4cb0-8bcb-48cbc67da8e4.jpg\n",
            " create mode 100644 data/images/train/24144448-f99a-4cb0-8bcb-48cbc67da8e4.xml\n",
            " create mode 100644 data/images/train/26b61ac3-2428-4257-a70c-9d4b9b15de23.jpg\n",
            " create mode 100644 data/images/train/26b61ac3-2428-4257-a70c-9d4b9b15de23.xml\n",
            " delete mode 100644 data/images/train/28989899-ed22-4abc-96ec-ffae09f98145.jpg\n",
            " create mode 100644 data/images/train/2fae3ab1-bf29-4ebe-8f09-9a7c854533dc.jpg\n",
            " create mode 100644 data/images/train/2fae3ab1-bf29-4ebe-8f09-9a7c854533dc.xml\n",
            " create mode 100644 data/images/train/4000652f-3991-4c12-af67-48afb050a541.jpg\n",
            " create mode 100644 data/images/train/4000652f-3991-4c12-af67-48afb050a541.xml\n",
            " create mode 100644 data/images/train/4068c54e-40c7-4489-840e-855f8d4cce46.jpg\n",
            " create mode 100644 data/images/train/4068c54e-40c7-4489-840e-855f8d4cce46.xml\n",
            " create mode 100644 data/images/train/43f766ca-5bc8-4f63-84dd-ce5ea67864ab.jpg\n",
            " create mode 100644 data/images/train/43f766ca-5bc8-4f63-84dd-ce5ea67864ab.xml\n",
            " create mode 100644 data/images/train/44d2f03a-56c6-4ca6-ad48-fcb208621a7f.jpg\n",
            " create mode 100644 data/images/train/44d2f03a-56c6-4ca6-ad48-fcb208621a7f.xml\n",
            " create mode 100644 data/images/train/4749d94a-2845-44e3-8975-443a52c99640.jpg\n",
            " create mode 100644 data/images/train/4749d94a-2845-44e3-8975-443a52c99640.xml\n",
            " create mode 100644 data/images/train/4794325c-758a-45e4-bcee-3196acbde876.jpg\n",
            " create mode 100644 data/images/train/4794325c-758a-45e4-bcee-3196acbde876.xml\n",
            " create mode 100644 data/images/train/4aa5bd90-ad56-4dfa-9088-7bd635d030b6.jpg\n",
            " create mode 100644 data/images/train/4aa5bd90-ad56-4dfa-9088-7bd635d030b6.xml\n",
            " delete mode 100644 data/images/train/51lc7DrLgpL._SX425_.jpg\n",
            " delete mode 100644 data/images/train/51p33bRuisL._SX342_.jpg\n",
            " create mode 100644 data/images/train/59ea66f8-a93f-4d4d-a43f-79a6f54c4e78.jpg\n",
            " create mode 100644 data/images/train/59ea66f8-a93f-4d4d-a43f-79a6f54c4e78.xml\n",
            " create mode 100644 data/images/train/5aeb717f-2d95-4b06-8062-7c7fd81f4d54.jpg\n",
            " create mode 100644 data/images/train/5aeb717f-2d95-4b06-8062-7c7fd81f4d54.xml\n",
            " create mode 100644 data/images/train/60c52a0a-c574-44ac-91f1-bd89760e8663.jpg\n",
            " create mode 100644 data/images/train/60c52a0a-c574-44ac-91f1-bd89760e8663.xml\n",
            " delete mode 100644 data/images/train/61CkxMiIzsL._AC_SX355_.jpg\n",
            " create mode 100644 data/images/train/622227d2-a8ac-49e7-acf5-50b6e5ed369f.jpg\n",
            " create mode 100644 data/images/train/622227d2-a8ac-49e7-acf5-50b6e5ed369f.xml\n",
            " create mode 100644 data/images/train/62a085f6-8759-4cef-abe5-f5dc417242ba.jpg\n",
            " create mode 100644 data/images/train/62a085f6-8759-4cef-abe5-f5dc417242ba.xml\n",
            " create mode 100644 data/images/train/6949c2d0-9af4-4a54-bd54-1b6bb3dfa778.jpg\n",
            " create mode 100644 data/images/train/6949c2d0-9af4-4a54-bd54-1b6bb3dfa778.xml\n",
            " create mode 100644 data/images/train/714af586-2fe1-4b2a-9f92-bf44d0e5b31c.jpg\n",
            " create mode 100644 data/images/train/714af586-2fe1-4b2a-9f92-bf44d0e5b31c.xml\n",
            " delete mode 100644 data/images/train/71cy2TFQu8L._SL1500_.jpg\n",
            " delete mode 100644 data/images/train/71cy2TFQu8L._SX355_.jpg\n",
            " create mode 100644 data/images/train/749102b4-aa6f-458a-8a7d-5104f016f8ed.jpg\n",
            " create mode 100644 data/images/train/749102b4-aa6f-458a-8a7d-5104f016f8ed.xml\n",
            " create mode 100644 data/images/train/776d7ee0-8e8f-4415-8eb2-bc0451c9b089.jpg\n",
            " create mode 100644 data/images/train/776d7ee0-8e8f-4415-8eb2-bc0451c9b089.xml\n",
            " create mode 100644 data/images/train/78babe87-7d87-4c13-9eec-aab373c6cddb.jpg\n",
            " create mode 100644 data/images/train/78babe87-7d87-4c13-9eec-aab373c6cddb.xml\n",
            " create mode 100644 data/images/train/79737503-7db5-4268-a8d7-fb80f42a68bc.jpg\n",
            " create mode 100644 data/images/train/79737503-7db5-4268-a8d7-fb80f42a68bc.xml\n",
            " create mode 100644 data/images/train/797a80c9-5154-468b-9ccf-90c8170290f9.jpg\n",
            " create mode 100644 data/images/train/797a80c9-5154-468b-9ccf-90c8170290f9.xml\n",
            " create mode 100644 data/images/train/8af14c37-64e0-452c-9432-6ccca33c33d0.jpg\n",
            " create mode 100644 data/images/train/8af14c37-64e0-452c-9432-6ccca33c33d0.xml\n",
            " create mode 100644 data/images/train/92b0d01b-6974-4924-a6ab-aa93c46cd60b.jpg\n",
            " create mode 100644 data/images/train/92b0d01b-6974-4924-a6ab-aa93c46cd60b.xml\n",
            " create mode 100644 data/images/train/9684f1f5-0fe8-4201-bcde-f602b68b6cf9.jpg\n",
            " create mode 100644 data/images/train/9684f1f5-0fe8-4201-bcde-f602b68b6cf9.xml\n",
            " create mode 100644 data/images/train/9aacb3ab-2bd8-42cb-aa3b-bd97dfb58908.jpg\n",
            " create mode 100644 data/images/train/9aacb3ab-2bd8-42cb-aa3b-bd97dfb58908.xml\n",
            " create mode 100644 data/images/train/9b0d2111-d33b-4ea7-a04b-b5aad7dab217.jpg\n",
            " create mode 100644 data/images/train/9b0d2111-d33b-4ea7-a04b-b5aad7dab217.xml\n",
            " create mode 100644 data/images/train/9b869b93-7d34-45a1-aa90-38461b44faa6.jpg\n",
            " create mode 100644 data/images/train/9b869b93-7d34-45a1-aa90-38461b44faa6.xml\n",
            " create mode 100644 data/images/train/9eaf56b7-3f0e-4786-a61c-cf112ca7d509.jpg\n",
            " create mode 100644 data/images/train/9eaf56b7-3f0e-4786-a61c-cf112ca7d509.xml\n",
            " delete mode 100644 data/images/train/A9BU_1_201911181371207187.jpg\n",
            " delete mode 100644 data/images/train/ARD__821_1188.jpg\n",
            " delete mode 100644 data/images/train/DISC1-Stm32f407__11873.1561068028.jpg\n",
            " delete mode 100644 data/images/train/ESP32 Development Board WiFi+Bluetooth-1000x750.jpg\n",
            " delete mode 100644 data/images/train/Esp32-Development-Board-WiFi-Bluetooth-Networking-Smart-Component-Esp-Wroom-32-Esp-32s.jpg\n",
            " delete mode 100644 data/images/train/HTB1Zruyee38SeJjSZFPq6A_vFXat.jpg\n",
            " create mode 100644 data/images/train/a53d02ce-1ca2-4685-ae8a-9603f8e3f23b.jpg\n",
            " create mode 100644 data/images/train/a53d02ce-1ca2-4685-ae8a-9603f8e3f23b.xml\n",
            " create mode 100644 data/images/train/a65bbcd1-8633-47e7-8e7c-ea40ca726dae.jpg\n",
            " create mode 100644 data/images/train/a65bbcd1-8633-47e7-8e7c-ea40ca726dae.xml\n",
            " create mode 100644 data/images/train/b169896b-c7e0-4487-8c17-05f5007054e9.jpg\n",
            " create mode 100644 data/images/train/b169896b-c7e0-4487-8c17-05f5007054e9.xml\n",
            " create mode 100644 data/images/train/b1f2763d-f5f2-420e-a1f4-11d4dc4d688f.jpg\n",
            " create mode 100644 data/images/train/b1f2763d-f5f2-420e-a1f4-11d4dc4d688f.xml\n",
            " create mode 100644 data/images/train/b25b4382-9fcc-41dc-a9ff-de053ccd4e26.jpg\n",
            " create mode 100644 data/images/train/b25b4382-9fcc-41dc-a9ff-de053ccd4e26.xml\n",
            " create mode 100644 data/images/train/b7ce7b11-3424-47d8-bd04-ef6600ce120b.jpg\n",
            " create mode 100644 data/images/train/b7ce7b11-3424-47d8-bd04-ef6600ce120b.xml\n",
            " create mode 100644 data/images/train/bea65fe4-2cfc-41fd-8a34-8a7fa746ee47.jpg\n",
            " create mode 100644 data/images/train/bea65fe4-2cfc-41fd-8a34-8a7fa746ee47.xml\n",
            " create mode 100644 data/images/train/bf8ad973-9984-4c18-92e0-934da85f8c0b.jpg\n",
            " create mode 100644 data/images/train/bf8ad973-9984-4c18-92e0-934da85f8c0b.xml\n",
            " create mode 100644 data/images/train/c464c486-1627-4759-a52d-0aeb988c2549.jpg\n",
            " create mode 100644 data/images/train/c464c486-1627-4759-a52d-0aeb988c2549.xml\n",
            " create mode 100644 data/images/train/c47e9ad0-a5e8-45dc-884d-3da883921a09.jpg\n",
            " create mode 100644 data/images/train/c47e9ad0-a5e8-45dc-884d-3da883921a09.xml\n",
            " create mode 100644 data/images/train/c5428add-9901-4102-b3f1-7c701cc6ddb3.jpg\n",
            " create mode 100644 data/images/train/c5428add-9901-4102-b3f1-7c701cc6ddb3.xml\n",
            " create mode 100644 data/images/train/c5bfdf9a-1e62-4fa8-965b-7a8cef000fdc.jpg\n",
            " create mode 100644 data/images/train/c5bfdf9a-1e62-4fa8-965b-7a8cef000fdc.xml\n",
            " create mode 100644 data/images/train/c68c5c53-eff8-41ad-b6f5-204351464e7c.jpg\n",
            " create mode 100644 data/images/train/c68c5c53-eff8-41ad-b6f5-204351464e7c.xml\n",
            " create mode 100644 data/images/train/d281a945-5eab-4630-ae5f-8bd2a0d01d22.jpg\n",
            " create mode 100644 data/images/train/d281a945-5eab-4630-ae5f-8bd2a0d01d22.xml\n",
            " create mode 100644 data/images/train/d4d6cd28-627b-434c-a0d2-ec983646434a.jpg\n",
            " create mode 100644 data/images/train/d4d6cd28-627b-434c-a0d2-ec983646434a.xml\n",
            " create mode 100644 data/images/train/d9edf430-7346-4dda-b274-e9ddcbeaa610.jpg\n",
            " create mode 100644 data/images/train/d9edf430-7346-4dda-b274-e9ddcbeaa610.xml\n",
            " create mode 100644 data/images/train/da24a855-6709-4096-932f-7c82f85b2219.jpg\n",
            " create mode 100644 data/images/train/da24a855-6709-4096-932f-7c82f85b2219.xml\n",
            " create mode 100644 data/images/train/dcbf1497-2d27-45ef-8705-ad476ce06bad.jpg\n",
            " create mode 100644 data/images/train/dcbf1497-2d27-45ef-8705-ad476ce06bad.xml\n",
            " delete mode 100644 data/images/train/download (1).jpg\n",
            " delete mode 100644 data/images/train/download (2).jpg\n",
            " delete mode 100644 data/images/train/download (3).jpg\n",
            " delete mode 100644 data/images/train/download (4).jpg\n",
            " delete mode 100644 data/images/train/download.jpg\n",
            " delete mode 100644 data/images/train/esp-32-development-board-wifi-bluetooth-ultra-low-power-500x500 (1).png\n",
            " delete mode 100644 data/images/train/esp-32-development-board-wifi-bluetooth-ultra-low-power-500x500.png\n",
            " delete mode 100644 data/images/train/esp32-wroom-development-board-wifibluetooth.jpg\n",
            " delete mode 100644 data/images/train/esp8266-esp-32-wroom-32.jpg\n",
            " delete mode 100644 data/images/train/images (2).jpg\n",
            " delete mode 100644 data/images/train/images (3).jpg\n",
            " delete mode 100644 data/images/train/images (4).jpg\n",
            " delete mode 100644 data/images/train/images (5).jpg\n",
            " delete mode 100644 data/images/train/images (6).jpg\n",
            " delete mode 100644 data/images/train/images.jpg\n",
            " delete mode 100644 data/images/train/mod-w5500_n.jpg\n",
            " delete mode 100644 data/images/train/stm32f4-discovery-kit-diger-kartlar-st-stm32f407g-disc1-9286-34-B.jpg\n",
            " delete mode 100644 data/images/train/stm32f4.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI8__uNS8-ns",
        "colab_type": "text"
      },
      "source": [
        "## Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecpHEnka8Kix",
        "colab_type": "code",
        "outputId": "b727f8ff-2c6e-4226-a68c-2742384a3e79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -q pycocotools\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "fatal: destination path 'models' already exists and is not an empty directory.\n",
            "/content/models/research\n",
            "object_detection/protos/input_reader.proto: warning: Import object_detection/protos/image_resizer.proto but not used.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-k7uGThXlny",
        "colab_type": "text"
      },
      "source": [
        "## Prepare `tfrecord` files\n",
        "\n",
        "Use the following scripts to generate the `tfrecord` files.\n",
        "```bash\n",
        "# Convert train folder annotation xml files to a single csv file,\n",
        "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
        "python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
        "\n",
        "# Convert test folder annotation xml files to a single csv.\n",
        "python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
        "\n",
        "# Generate `train.record`\n",
        "python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
        "\n",
        "# Generate `test.record`\n",
        "python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezGDABRXXhPP",
        "colab_type": "code",
        "outputId": "5077c234-f911-4ed8-87c8-9c8160f19fd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        }
      },
      "source": [
        "%cd {repo_dir_path}\n",
        "\n",
        "# Convert train folder annotation xml files to a single csv file,\n",
        "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
        "!python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
        "\n",
        "# Convert test folder annotation xml files to a single csv.\n",
        "!python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
        "\n",
        "# Generate `train.record`\n",
        "!python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
        "\n",
        "# Generate `test.record`\n",
        "!python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/boardDetection\n",
            "Successfully converted xml to csv.\n",
            "Generate `data/annotations/label_map.pbtxt`\n",
            "Successfully converted xml to csv.\n",
            "WARNING:tensorflow:From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0513 16:49:16.932907 140107376871296 module_wrapper.py:139] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0513 16:49:16.971725 140107376871296 module_wrapper.py:139] From generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/boardDetection/data/annotations/train.record\n",
            "WARNING:tensorflow:From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0513 16:49:21.679125 140069774579584 module_wrapper.py:139] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0513 16:49:21.697366 140069774579584 module_wrapper.py:139] From generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/boardDetection/data/annotations/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgd-fzAIkZlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_record_fname = '/content/boardDetection/data/annotations/test.record'\n",
        "train_record_fname = '/content/boardDetection/data/annotations/train.record'\n",
        "label_map_pbtxt_fname = '/content/boardDetection/data/annotations/label_map.pbtxt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCNYAaC7w6N8",
        "colab_type": "text"
      },
      "source": [
        "## Download base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orDCj6ihgUMR",
        "colab_type": "code",
        "outputId": "29c57e33-b6ae-4ad1-e9d1-4b201e3aeec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGhvAObeiIix",
        "colab_type": "code",
        "outputId": "58f30ef3-5465-4adb-cc5f-247b988b30c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/pretrained_model\n",
            "total 135M\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 .\n",
            "drwxr-xr-x 64 root   root  4.0K May 13 16:49 ..\n",
            "-rw-r--r--  1 345018 89939   77 Mar 30  2018 checkpoint\n",
            "-rw-r--r--  1 345018 89939  67M Mar 30  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 89939  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 89939  15K Mar 30  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 89939 3.4M Mar 30  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 89939 4.2K Mar 30  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHnxlfRznPP3",
        "colab_type": "code",
        "outputId": "5f479089-103e-4000-8b38-a3bd850327a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models/research/pretrained_model/model.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvwtHlLOeRJD",
        "colab_type": "text"
      },
      "source": [
        "## Configuring a Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIhw7IdpLuiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG1nCNpUXcRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjtCbLF2i0wI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    f.write(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH0MEEanocn6",
        "colab_type": "code",
        "outputId": "e751f08e-e6aa-44de-91a7-d4334107e0cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!cat {pipeline_fname}"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  ssd {\n",
            "    num_classes: 3\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    anchor_generator {\n",
            "      ssd_anchor_generator {\n",
            "        num_layers: 6\n",
            "        min_scale: 0.2\n",
            "        max_scale: 0.95\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        aspect_ratios: 3.0\n",
            "        aspect_ratios: 0.3333\n",
            "      }\n",
            "    }\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 300\n",
            "        width: 300\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      convolutional_box_predictor {\n",
            "        min_depth: 0\n",
            "        max_depth: 0\n",
            "        num_layers_before_predictor: 0\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 0.8\n",
            "        kernel_size: 1\n",
            "        box_code_size: 4\n",
            "        apply_sigmoid_to_scores: false\n",
            "        conv_hyperparams {\n",
            "          activation: RELU_6,\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.00004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            truncated_normal_initializer {\n",
            "              stddev: 0.03\n",
            "              mean: 0.0\n",
            "            }\n",
            "          }\n",
            "          batch_norm {\n",
            "            train: true,\n",
            "            scale: true,\n",
            "            center: true,\n",
            "            decay: 0.9997,\n",
            "            epsilon: 0.001,\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'ssd_mobilenet_v2'\n",
            "      min_depth: 16\n",
            "      depth_multiplier: 1.0\n",
            "      conv_hyperparams {\n",
            "        activation: RELU_6,\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.00004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            stddev: 0.03\n",
            "            mean: 0.0\n",
            "          }\n",
            "        }\n",
            "        batch_norm {\n",
            "          train: true,\n",
            "          scale: true,\n",
            "          center: true,\n",
            "          decay: 0.9997,\n",
            "          epsilon: 0.001,\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    loss {\n",
            "      classification_loss {\n",
            "        weighted_sigmoid {\n",
            "        }\n",
            "      }\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      hard_example_miner {\n",
            "        num_hard_examples: 3000\n",
            "        iou_threshold: 0.99\n",
            "        loss_type: CLASSIFICATION\n",
            "        max_negatives_per_positive: 3\n",
            "        min_negatives_per_image: 3\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-8\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 12\n",
            "  optimizer {\n",
            "    rms_prop_optimizer: {\n",
            "      learning_rate: {\n",
            "        exponential_decay_learning_rate {\n",
            "          initial_learning_rate: 0.004\n",
            "          decay_steps: 800720\n",
            "          decay_factor: 0.95\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "      decay: 0.9\n",
            "      epsilon: 1.0\n",
            "    }\n",
            "  }\n",
            "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
            "  fine_tune_checkpoint_type:  \"detection\"\n",
            "  # Note: The below line limits the training process to 200K steps, which we\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\n",
            "  # never decay). Remove the below line to train indefinitely.\n",
            "  num_steps: 10000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    ssd_random_crop {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/boardDetection/data/annotations/train.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/boardDetection/data/annotations/label_map.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  num_examples: 8000\n",
            "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
            "  # Remove the below line to evaluate indefinitely.\n",
            "  max_evals: 10\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/boardDetection/data/annotations/test.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/boardDetection/data/annotations/label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f11w0uO3jFCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dir = 'training/'\n",
        "# Optionally remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23TECXvNezIF",
        "colab_type": "text"
      },
      "source": [
        "## Run Tensorboard(Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H2PZs-mSCmO",
        "colab_type": "code",
        "outputId": "2c0f0b86-e3c5-452a-b2c9-f1693e3b9d49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-13 16:49:41--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.86.229.42, 54.84.72.55, 34.234.238.166, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.86.229.42|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ngrok-stable-linux-amd64.zip.1\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  13.3MB/s    in 1.0s    \n",
            "\n",
            "2020-05-13 16:49:42 (13.3 MB/s) - ngrok-stable-linux-amd64.zip.1 saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8o6r1o5SC5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR = model_dir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge1OX7gcSC7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5GSGxZNh8rp",
        "colab_type": "text"
      },
      "source": [
        "### Get Tensorboard link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjhPT9iPSJ6T",
        "colab_type": "code",
        "outputId": "18f18c95-c55c-4bfd-9758-a2a4a260ad12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://8abbe812.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDddx2rPfex9",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC7_syR1SJ9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjDHjhKQofT5",
        "colab_type": "code",
        "outputId": "945fa53f-23db-4ec0-a104-b908c53e4bec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/models/research/object_detection/model_main.py:109: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:137: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0513 16:49:52.589924 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:137: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:685: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "W0513 16:49:52.594830 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:685: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0513 16:49:52.595014 140213080639360 model_lib.py:686] Forced number of epochs for all eval validations to be 1.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:523: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0513 16:49:52.595213 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:523: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 10000\n",
            "I0513 16:49:52.595351 140213080639360 config_util.py:523] Maybe overwriting train_steps: 10000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0513 16:49:52.595525 140213080639360 config_util.py:523] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0513 16:49:52.595699 140213080639360 config_util.py:523] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0513 16:49:52.595861 140213080639360 config_util.py:523] Maybe overwriting eval_num_epochs: 1\n",
            "INFO:tensorflow:Maybe overwriting load_pretrained: True\n",
            "I0513 16:49:52.595992 140213080639360 config_util.py:523] Maybe overwriting load_pretrained: True\n",
            "INFO:tensorflow:Ignoring config override key: load_pretrained\n",
            "I0513 16:49:52.596130 140213080639360 config_util.py:533] Ignoring config override key: load_pretrained\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0513 16:49:52.597211 140213080639360 model_lib.py:702] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "I0513 16:49:52.597395 140213080639360 model_lib.py:737] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8598632ac8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0513 16:49:52.598093 140213080639360 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8598632ac8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f857e5a61e0>) includes params argument, but params are not passed to Estimator.\n",
            "W0513 16:49:52.598384 140213080639360 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f857e5a61e0>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0513 16:49:52.599273 140213080639360 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0513 16:49:52.599533 140213080639360 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0513 16:49:52.599913 140213080639360 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0513 16:49:52.615180 140213080639360 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:208: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0513 16:49:52.629138 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:208: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:223: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "W0513 16:49:52.629453 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:223: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:76: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0513 16:49:52.644669 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/builders/dataset_builder.py:76: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0513 16:49:52.645796 140213080639360 dataset_builder.py:84] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0513 16:49:52.652811 140213080639360 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0513 16:49:52.653043 140213080639360 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:182: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0513 16:49:52.678020 140213080639360 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:182: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:Entity <function build.<locals>.process_fn at 0x7f8585eb8b70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0513 16:49:52.700996 140213080639360 ag_logging.py:146] Entity <function build.<locals>.process_fn at 0x7f8585eb8b70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:498: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
            "\n",
            "W0513 16:49:52.922833 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/utils/ops.py:498: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:500: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0513 16:49:52.927156 140213080639360 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:500: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:634: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0513 16:49:52.979199 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:634: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:198: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0513 16:49:53.045297 140213080639360 deprecation.py:323] From /content/models/research/object_detection/core/preprocessor.py:198: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:3030: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0513 16:49:53.989036 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:3030: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:246: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0513 16:49:54.008630 140213080639360 deprecation.py:323] From /content/models/research/object_detection/inputs.py:246: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:603: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n",
            "\n",
            "W0513 16:49:54.637129 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/inputs.py:603: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:185: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "W0513 16:49:54.683074 140213080639360 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:185: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0513 16:49:54.700298 140213080639360 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:600: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "W0513 16:49:54.913371 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:600: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:608: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0513 16:49:54.913728 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:608: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0513 16:49:54.917667 140213080639360 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W0513 16:49:58.194373 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0513 16:49:58.208186 140213080639360 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0513 16:49:58.249032 140213080639360 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0513 16:49:58.289387 140213080639360 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0513 16:49:58.328682 140213080639360 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0513 16:49:58.368534 140213080639360 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0513 16:49:58.407727 140213080639360 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/variables_helper.py:178: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "W0513 16:49:58.452183 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/utils/variables_helper.py:178: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/variables_helper.py:138: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "W0513 16:49:58.453420 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/utils/variables_helper.py:138: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "W0513 16:49:58.461775 140213080639360 variables_helper.py:153] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 512]], model variable shape: [[3, 3, 256, 512]]. This variable will not be initialized from the checkpoint.\n",
            "W0513 16:49:58.462098 140213080639360 variables_helper.py:153] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n",
            "W0513 16:49:58.462332 140213080639360 variables_helper.py:153] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n",
            "W0513 16:49:58.462548 140213080639360 variables_helper.py:153] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 64, 128]], model variable shape: [[3, 3, 64, 128]]. This variable will not be initialized from the checkpoint.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:402: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "W0513 16:49:58.462879 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:402: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0513 16:49:59.774197 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0513 16:50:01.957312 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:178: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "W0513 16:50:01.964036 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:178: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:184: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
            "\n",
            "W0513 16:50:01.965410 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:184: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1275: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "W0513 16:50:02.341153 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1275: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:434: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0513 16:50:02.344476 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:434: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "W0513 16:50:02.344818 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/optimizer_builder.py:48: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
            "\n",
            "W0513 16:50:02.355023 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/builders/optimizer_builder.py:48: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:451: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "W0513 16:50:02.355292 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:451: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0513 16:50:04.708506 140213080639360 deprecation.py:506] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:572: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0513 16:50:11.773546 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:572: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:576: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "W0513 16:50:12.624333 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:576: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:577: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "W0513 16:50:12.624664 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:577: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0513 16:50:12.625186 140213080639360 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0513 16:50:12.626630 140213080639360 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0513 16:50:16.876835 140213080639360 monitored_session.py:240] Graph was finalized.\n",
            "2020-05-13 16:50:16.892054: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-05-13 16:50:16.892397: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1d49d40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-13 16:50:16.892434: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-05-13 16:50:16.898101: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-05-13 16:50:17.023402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 16:50:17.024286: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1d49b80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-13 16:50:17.024320: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-05-13 16:50:17.025797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 16:50:17.026483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-13 16:50:17.026929: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-13 16:50:17.301137: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-13 16:50:17.449535: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-13 16:50:17.484221: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-13 16:50:17.732982: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-13 16:50:17.778774: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-13 16:50:18.290241: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-13 16:50:18.290519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 16:50:18.291402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 16:50:18.292109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-13 16:50:18.297306: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-13 16:50:18.299148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-13 16:50:18.299190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-05-13 16:50:18.299217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-05-13 16:50:18.300542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 16:50:18.301419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 16:50:18.302170: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-05-13 16:50:18.302236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0513 16:50:28.673905 140213080639360 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0513 16:50:29.078958 140213080639360 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n",
            "I0513 16:50:41.330124 140213080639360 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n",
            "2020-05-13 16:50:50.933263: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-13 16:50:55.100829: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "INFO:tensorflow:loss = 20.101362, step = 0\n",
            "I0513 16:50:58.402354 140213080639360 basic_session_run_hooks.py:262] loss = 20.101362, step = 0\n",
            "INFO:tensorflow:global_step/sec: 2.16545\n",
            "I0513 16:51:44.581165 140213080639360 basic_session_run_hooks.py:692] global_step/sec: 2.16545\n",
            "INFO:tensorflow:loss = 3.1951609, step = 100 (46.180 sec)\n",
            "I0513 16:51:44.582524 140213080639360 basic_session_run_hooks.py:260] loss = 3.1951609, step = 100 (46.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.40288\n",
            "I0513 16:52:26.198039 140213080639360 basic_session_run_hooks.py:692] global_step/sec: 2.40288\n",
            "INFO:tensorflow:loss = 2.2736337, step = 200 (41.617 sec)\n",
            "I0513 16:52:26.199445 140213080639360 basic_session_run_hooks.py:260] loss = 2.2736337, step = 200 (41.617 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.4348\n",
            "I0513 16:53:07.269165 140213080639360 basic_session_run_hooks.py:692] global_step/sec: 2.4348\n",
            "INFO:tensorflow:loss = 2.1799676, step = 300 (41.071 sec)\n",
            "I0513 16:53:07.270357 140213080639360 basic_session_run_hooks.py:260] loss = 2.1799676, step = 300 (41.071 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.41266\n",
            "I0513 16:53:48.717164 140213080639360 basic_session_run_hooks.py:692] global_step/sec: 2.41266\n",
            "INFO:tensorflow:loss = 2.2001603, step = 400 (41.448 sec)\n",
            "I0513 16:53:48.718508 140213080639360 basic_session_run_hooks.py:260] loss = 2.2001603, step = 400 (41.448 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.4151\n",
            "I0513 16:54:30.123357 140213080639360 basic_session_run_hooks.py:692] global_step/sec: 2.4151\n",
            "INFO:tensorflow:loss = 1.9112645, step = 500 (41.406 sec)\n",
            "I0513 16:54:30.124685 140213080639360 basic_session_run_hooks.py:260] loss = 1.9112645, step = 500 (41.406 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.4217\n",
            "I0513 16:55:11.416692 140213080639360 basic_session_run_hooks.py:692] global_step/sec: 2.4217\n",
            "INFO:tensorflow:loss = 2.5735962, step = 600 (41.293 sec)\n",
            "I0513 16:55:11.417862 140213080639360 basic_session_run_hooks.py:260] loss = 2.5735962, step = 600 (41.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.43914\n",
            "I0513 16:55:52.414792 140213080639360 basic_session_run_hooks.py:692] global_step/sec: 2.43914\n",
            "INFO:tensorflow:loss = 1.2195215, step = 700 (40.998 sec)\n",
            "I0513 16:55:52.416033 140213080639360 basic_session_run_hooks.py:260] loss = 1.2195215, step = 700 (40.998 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.42279\n",
            "I0513 16:56:33.689537 140213080639360 basic_session_run_hooks.py:692] global_step/sec: 2.42279\n",
            "INFO:tensorflow:loss = 2.983222, step = 800 (41.275 sec)\n",
            "I0513 16:56:33.690810 140213080639360 basic_session_run_hooks.py:260] loss = 2.983222, step = 800 (41.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.42185\n",
            "I0513 16:57:14.980306 140213080639360 basic_session_run_hooks.py:692] global_step/sec: 2.42185\n",
            "INFO:tensorflow:loss = 0.93717283, step = 900 (41.291 sec)\n",
            "I0513 16:57:14.981961 140213080639360 basic_session_run_hooks.py:260] loss = 0.93717283, step = 900 (41.291 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.46186\n",
            "I0513 16:57:55.599968 140213080639360 basic_session_run_hooks.py:692] global_step/sec: 2.46186\n",
            "INFO:tensorflow:loss = 0.95034695, step = 1000 (40.621 sec)\n",
            "I0513 16:57:55.602966 140213080639360 basic_session_run_hooks.py:260] loss = 0.95034695, step = 1000 (40.621 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.42768\n",
            "I0513 16:58:36.791483 140213080639360 basic_session_run_hooks.py:692] global_step/sec: 2.42768\n",
            "INFO:tensorflow:loss = 1.0743146, step = 1100 (41.190 sec)\n",
            "I0513 16:58:36.792975 140213080639360 basic_session_run_hooks.py:260] loss = 1.0743146, step = 1100 (41.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.4379\n",
            "I0513 16:59:17.810442 140213080639360 basic_session_run_hooks.py:692] global_step/sec: 2.4379\n",
            "INFO:tensorflow:loss = 1.1827865, step = 1200 (41.019 sec)\n",
            "I0513 16:59:17.811663 140213080639360 basic_session_run_hooks.py:260] loss = 1.1827865, step = 1200 (41.019 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.41679\n",
            "I0513 16:59:59.187742 140213080639360 basic_session_run_hooks.py:692] global_step/sec: 2.41679\n",
            "INFO:tensorflow:loss = 1.4250585, step = 1300 (41.377 sec)\n",
            "I0513 16:59:59.188921 140213080639360 basic_session_run_hooks.py:260] loss = 1.4250585, step = 1300 (41.377 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.43357\n",
            "I0513 17:00:40.279516 140213080639360 basic_session_run_hooks.py:692] global_step/sec: 2.43357\n",
            "INFO:tensorflow:loss = 1.1430807, step = 1400 (41.092 sec)\n",
            "I0513 17:00:40.280894 140213080639360 basic_session_run_hooks.py:260] loss = 1.1430807, step = 1400 (41.092 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1411 into training/model.ckpt.\n",
            "I0513 17:00:44.392525 140213080639360 basic_session_run_hooks.py:606] Saving checkpoints for 1411 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <function build.<locals>.process_fn at 0x7f85778d6d08> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0513 17:00:46.196211 140213080639360 ag_logging.py:146] Entity <function build.<locals>.process_fn at 0x7f85778d6d08> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0513 17:00:46.982029 140213080639360 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0513 17:00:49.661338 140213080639360 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0513 17:00:49.702209 140213080639360 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0513 17:00:49.740654 140213080639360 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0513 17:00:49.780135 140213080639360 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0513 17:00:49.821019 140213080639360 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0513 17:00:49.858171 140213080639360 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:819: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0513 17:00:50.829382 140213080639360 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:819: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0513 17:00:51.085308 140213080639360 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:1293: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
            "\n",
            "W0513 17:00:51.266459 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/utils/visualization_utils.py:1293: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:541: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "W0513 17:00:51.366646 140213080639360 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:541: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0513 17:00:51.717406 140213080639360 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-05-13T17:00:51Z\n",
            "I0513 17:00:51.737402 140213080639360 evaluation.py:255] Starting evaluation at 2020-05-13T17:00:51Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0513 17:00:52.257676 140213080639360 monitored_session.py:240] Graph was finalized.\n",
            "2020-05-13 17:00:52.259015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 17:00:52.259631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-13 17:00:52.259740: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-13 17:00:52.259785: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-13 17:00:52.259828: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-13 17:00:52.259873: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-13 17:00:52.259914: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-13 17:00:52.259953: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-13 17:00:52.259995: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-13 17:00:52.260146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 17:00:52.260783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 17:00:52.261304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-13 17:00:52.261366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-13 17:00:52.261387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-05-13 17:00:52.261402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-05-13 17:00:52.261581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 17:00:52.262196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 17:00:52.262736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-1411\n",
            "I0513 17:00:52.263994 140213080639360 saver.py:1284] Restoring parameters from training/model.ckpt-1411\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0513 17:00:53.304332 140213080639360 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0513 17:00:53.469368 140213080639360 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 11 images.\n",
            "I0513 17:00:56.895317 140211096925952 coco_evaluation.py:236] Performing evaluation on 11 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0513 17:00:56.895929 140211096925952 coco_tools.py:115] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0513 17:00:56.897546 140211096925952 coco_tools.py:137] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "2020-05-13 17:00:56.916652: W tensorflow/core/framework/op_kernel.cc:1639] Invalid argument: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 117, in linspace\n",
            "    num = operator.index(num)\n",
            "\n",
            "TypeError: 'numpy.float64' object cannot be interpreted as an integer\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n",
            "    ret = func(*args)\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_evaluation.py\", line 415, in first_value_func\n",
            "    self._metrics = self.evaluate()\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_evaluation.py\", line 246, in evaluate\n",
            "    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_tools.py\", line 177, in __init__\n",
            "    cocoeval.COCOeval.__init__(self, groundtruth, detections, iouType=iou_type)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 76, in __init__\n",
            "    self.params = Params(iouType=iouType) # parameters\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 527, in __init__\n",
            "    self.setDetParams()\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\n",
            "    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\n",
            "\n",
            "  File \"<__array_function__ internals>\", line 6, in linspace\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 121, in linspace\n",
            "    .format(type(num)))\n",
            "\n",
            "TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
            "\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
            "    target_list, run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "tensorflow.python.framework.errors_impl.OutOfRangeError: 2 root error(s) found.\n",
            "  (0) Out of range: End of sequence\n",
            "\t [[{{node IteratorGetNext}}]]\n",
            "  (1) Out of range: End of sequence\n",
            "\t [[{{node IteratorGetNext}}]]\n",
            "\t [[IteratorGetNext/_2011]]\n",
            "0 successful operations.\n",
            "0 derived errors ignored.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/evaluation.py\", line 272, in _evaluate_once\n",
            "    session.run(eval_ops, feed_dict)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 754, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1360, in run\n",
            "    raise six.reraise(*original_exc_info)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/six.py\", line 693, in reraise\n",
            "    raise value\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1418, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1176, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 956, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1384, in _do_call\n",
            "    raise type(e)(node_def, op, message)\n",
            "tensorflow.python.framework.errors_impl.OutOfRangeError: 2 root error(s) found.\n",
            "  (0) Out of range: End of sequence\n",
            "\t [[node IteratorGetNext (defined at tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n",
            "  (1) Out of range: End of sequence\n",
            "\t [[node IteratorGetNext (defined at tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n",
            "\t [[IteratorGetNext/_2011]]\n",
            "0 successful operations.\n",
            "0 derived errors ignored.\n",
            "\n",
            "Original stack trace for 'IteratorGetNext':\n",
            "  File \"content/models/research/object_detection/model_main.py\", line 109, in <module>\n",
            "    tf.app.run()\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"content/models/research/object_detection/model_main.py\", line 105, in main\n",
            "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n",
            "    return executor.run()\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 613, in run\n",
            "    return self.run_local()\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\n",
            "    saving_listeners=saving_listeners)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n",
            "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n",
            "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\n",
            "    saving_listeners)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\n",
            "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 754, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1426, in run\n",
            "    run_metadata=run_metadata))\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/training/basic_session_run_hooks.py\", line 594, in after_run\n",
            "    if self._save(run_context.session, global_step):\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/training/basic_session_run_hooks.py\", line 619, in _save\n",
            "    if l.after_save(session, step):\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 519, in after_save\n",
            "    self._evaluate(global_step_value)  # updates self.eval_result\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 539, in _evaluate\n",
            "    self._evaluator.evaluate_and_export())\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 920, in evaluate_and_export\n",
            "    hooks=self._eval_spec.hooks)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 480, in evaluate\n",
            "    name=name)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 522, in _actual_eval\n",
            "    return _evaluate()\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 504, in _evaluate\n",
            "    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1511, in _evaluate_build_graph\n",
            "    self._call_model_fn_eval(input_fn, self.config))\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1544, in _call_model_fn_eval\n",
            "    input_fn, ModeKeys.EVAL)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1025, in _get_features_and_labels_from_input_fn\n",
            "    self._call_input_fn(input_fn, mode))\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/util.py\", line 65, in parse_input_fn_result\n",
            "    result = iterator.get_next()\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/data/ops/iterator_ops.py\", line 426, in get_next\n",
            "    name=name)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/gen_dataset_ops.py\", line 2518, in iterator_get_next\n",
            "    output_shapes=output_shapes, name=name)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n",
            "    op_def=op_def)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n",
            "    attrs, op_def, compute_device)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n",
            "    op_def=op_def)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n",
            "    self._traceback = tf_stack.extract_stack()\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
            "    target_list, run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\n",
            "  (0) Invalid argument: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 117, in linspace\n",
            "    num = operator.index(num)\n",
            "\n",
            "TypeError: 'numpy.float64' object cannot be interpreted as an integer\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n",
            "    ret = func(*args)\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_evaluation.py\", line 415, in first_value_func\n",
            "    self._metrics = self.evaluate()\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_evaluation.py\", line 246, in evaluate\n",
            "    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_tools.py\", line 177, in __init__\n",
            "    cocoeval.COCOeval.__init__(self, groundtruth, detections, iouType=iou_type)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 76, in __init__\n",
            "    self.params = Params(iouType=iouType) # parameters\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 527, in __init__\n",
            "    self.setDetParams()\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\n",
            "    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\n",
            "\n",
            "  File \"<__array_function__ internals>\", line 6, in linspace\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 121, in linspace\n",
            "    .format(type(num)))\n",
            "\n",
            "TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
            "\n",
            "\n",
            "\t [[{{node PyFunc_3}}]]\n",
            "\t [[cond_7/Const/_2489]]\n",
            "  (1) Invalid argument: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 117, in linspace\n",
            "    num = operator.index(num)\n",
            "\n",
            "TypeError: 'numpy.float64' object cannot be interpreted as an integer\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n",
            "    ret = func(*args)\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_evaluation.py\", line 415, in first_value_func\n",
            "    self._metrics = self.evaluate()\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_evaluation.py\", line 246, in evaluate\n",
            "    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_tools.py\", line 177, in __init__\n",
            "    cocoeval.COCOeval.__init__(self, groundtruth, detections, iouType=iou_type)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 76, in __init__\n",
            "    self.params = Params(iouType=iouType) # parameters\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 527, in __init__\n",
            "    self.setDetParams()\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\n",
            "    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\n",
            "\n",
            "  File \"<__array_function__ internals>\", line 6, in linspace\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 121, in linspace\n",
            "    .format(type(num)))\n",
            "\n",
            "TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
            "\n",
            "\n",
            "\t [[{{node PyFunc_3}}]]\n",
            "0 successful operations.\n",
            "0 derived errors ignored.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/models/research/object_detection/model_main.py\", line 109, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/models/research/object_detection/model_main.py\", line 105, in main\n",
            "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n",
            "    return executor.run()\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 613, in run\n",
            "    return self.run_local()\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\n",
            "    saving_listeners=saving_listeners)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n",
            "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n",
            "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\n",
            "    saving_listeners)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\n",
            "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 754, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1360, in run\n",
            "    raise six.reraise(*original_exc_info)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/six.py\", line 693, in reraise\n",
            "    raise value\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1426, in run\n",
            "    run_metadata=run_metadata))\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/basic_session_run_hooks.py\", line 594, in after_run\n",
            "    if self._save(run_context.session, global_step):\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/basic_session_run_hooks.py\", line 619, in _save\n",
            "    if l.after_save(session, step):\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 519, in after_save\n",
            "    self._evaluate(global_step_value)  # updates self.eval_result\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 539, in _evaluate\n",
            "    self._evaluator.evaluate_and_export())\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 920, in evaluate_and_export\n",
            "    hooks=self._eval_spec.hooks)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 480, in evaluate\n",
            "    name=name)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 522, in _actual_eval\n",
            "    return _evaluate()\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _evaluate\n",
            "    output_dir=self.eval_dir(name))\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1619, in _evaluate_run\n",
            "    config=self._session_config)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/evaluation.py\", line 272, in _evaluate_once\n",
            "    session.run(eval_ops, feed_dict)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 861, in __exit__\n",
            "    self._close_internal(exception_type)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 894, in _close_internal\n",
            "    h.end(self._coordinated_creator.tf_sess)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/basic_session_run_hooks.py\", line 951, in end\n",
            "    self._final_ops, feed_dict=self._final_ops_feed_dict)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 956, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1384, in _do_call\n",
            "    raise type(e)(node_def, op, message)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\n",
            "  (0) Invalid argument: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 117, in linspace\n",
            "    num = operator.index(num)\n",
            "\n",
            "TypeError: 'numpy.float64' object cannot be interpreted as an integer\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n",
            "    ret = func(*args)\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_evaluation.py\", line 415, in first_value_func\n",
            "    self._metrics = self.evaluate()\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_evaluation.py\", line 246, in evaluate\n",
            "    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_tools.py\", line 177, in __init__\n",
            "    cocoeval.COCOeval.__init__(self, groundtruth, detections, iouType=iou_type)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 76, in __init__\n",
            "    self.params = Params(iouType=iouType) # parameters\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 527, in __init__\n",
            "    self.setDetParams()\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\n",
            "    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\n",
            "\n",
            "  File \"<__array_function__ internals>\", line 6, in linspace\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 121, in linspace\n",
            "    .format(type(num)))\n",
            "\n",
            "TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
            "\n",
            "\n",
            "\t [[node PyFunc_3 (defined at tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n",
            "\t [[cond_7/Const/_2489]]\n",
            "  (1) Invalid argument: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 117, in linspace\n",
            "    num = operator.index(num)\n",
            "\n",
            "TypeError: 'numpy.float64' object cannot be interpreted as an integer\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n",
            "    ret = func(*args)\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_evaluation.py\", line 415, in first_value_func\n",
            "    self._metrics = self.evaluate()\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_evaluation.py\", line 246, in evaluate\n",
            "    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_tools.py\", line 177, in __init__\n",
            "    cocoeval.COCOeval.__init__(self, groundtruth, detections, iouType=iou_type)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 76, in __init__\n",
            "    self.params = Params(iouType=iouType) # parameters\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 527, in __init__\n",
            "    self.setDetParams()\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\n",
            "    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\n",
            "\n",
            "  File \"<__array_function__ internals>\", line 6, in linspace\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 121, in linspace\n",
            "    .format(type(num)))\n",
            "\n",
            "TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
            "\n",
            "\n",
            "\t [[node PyFunc_3 (defined at tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n",
            "0 successful operations.\n",
            "0 derived errors ignored.\n",
            "\n",
            "Original stack trace for 'PyFunc_3':\n",
            "  File \"content/models/research/object_detection/model_main.py\", line 109, in <module>\n",
            "    tf.app.run()\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"content/models/research/object_detection/model_main.py\", line 105, in main\n",
            "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n",
            "    return executor.run()\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 613, in run\n",
            "    return self.run_local()\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\n",
            "    saving_listeners=saving_listeners)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n",
            "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n",
            "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\n",
            "    saving_listeners)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\n",
            "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 754, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1426, in run\n",
            "    run_metadata=run_metadata))\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/training/basic_session_run_hooks.py\", line 594, in after_run\n",
            "    if self._save(run_context.session, global_step):\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/training/basic_session_run_hooks.py\", line 619, in _save\n",
            "    if l.after_save(session, step):\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 519, in after_save\n",
            "    self._evaluate(global_step_value)  # updates self.eval_result\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 539, in _evaluate\n",
            "    self._evaluator.evaluate_and_export())\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 920, in evaluate_and_export\n",
            "    hooks=self._eval_spec.hooks)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 480, in evaluate\n",
            "    name=name)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 522, in _actual_eval\n",
            "    return _evaluate()\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 504, in _evaluate\n",
            "    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1511, in _evaluate_build_graph\n",
            "    self._call_model_fn_eval(input_fn, self.config))\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1547, in _call_model_fn_eval\n",
            "    features, labels, ModeKeys.EVAL, config)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1149, in _call_model_fn\n",
            "    model_fn_results = self._model_fn(features=features, **kwargs)\n",
            "  File \"content/models/research/object_detection/model_lib.py\", line 539, in model_fn\n",
            "    eval_config, list(category_index.values()), eval_dict)\n",
            "  File \"content/models/research/object_detection/eval_util.py\", line 1034, in get_eval_metric_ops_for_evaluators\n",
            "    eval_dict))\n",
            "  File \"content/models/research/object_detection/metrics/coco_evaluation.py\", line 425, in get_estimator_eval_metric_ops\n",
            "    first_value_op = tf.py_func(first_value_func, [], tf.float32)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/script_ops.py\", line 513, in py_func\n",
            "    return py_func_common(func, inp, Tout, stateful, name=name)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/script_ops.py\", line 495, in py_func_common\n",
            "    func=func, inp=inp, Tout=Tout, stateful=stateful, eager=False, name=name)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/script_ops.py\", line 318, in _internal_py_func\n",
            "    input=inp, token=token, Tout=Tout, name=name)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/gen_script_ops.py\", line 170, in py_func\n",
            "    \"PyFunc\", input=input, token=token, Tout=Tout, name=name)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n",
            "    op_def=op_def)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n",
            "    attrs, op_def, compute_device)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n",
            "    op_def=op_def)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n",
            "    self._traceback = tf_stack.extract_stack()\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP-tUdtnRybs",
        "colab_type": "code",
        "outputId": "c9b03aa5-6da3-432e-da51-f5adc34f605c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "!ls {model_dir}"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\n",
            "events.out.tfevents.1589388613.69eb7e9d902a\n",
            "graph.pbtxt\n",
            "model.ckpt-0.data-00000-of-00001\n",
            "model.ckpt-0.index\n",
            "model.ckpt-0.meta\n",
            "model.ckpt-1411.data-00000-of-00001\n",
            "model.ckpt-1411.index\n",
            "model.ckpt-1411.meta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1Nrqw3nqnCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Legacy way of training(also works).\n",
        "# !python /content/models/research/object_detection/legacy/train.py --logtostderr --train_dir={model_dir} --pipeline_config_path={pipeline_fname}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmSESMetj1sa",
        "colab_type": "text"
      },
      "source": [
        "## Exporting a Trained Inference Graph\n",
        "Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHoP90pUyKSq",
        "colab_type": "code",
        "outputId": "ed9892b3-2f84-4bce-9714-1a2b7d61785b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = './fine_tuned_model'\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training/model.ckpt-1411\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0513 17:01:07.953403 139762618615680 module_wrapper.py:139] From /content/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:419: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0513 17:01:07.960625 139762618615680 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:419: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:138: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0513 17:01:07.960986 139762618615680 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:138: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:3030: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0513 17:01:07.999177 139762618615680 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:3030: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:600: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "W0513 17:01:08.031165 139762618615680 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:600: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:608: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0513 17:01:08.031499 139762618615680 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:608: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0513 17:01:08.034579 139762618615680 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W0513 17:01:10.683549 139762618615680 module_wrapper.py:139] From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:157: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0513 17:01:10.696664 139762618615680 module_wrapper.py:139] From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:157: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0513 17:01:10.696892 139762618615680 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0513 17:01:10.743988 139762618615680 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0513 17:01:10.791782 139762618615680 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0513 17:01:10.837925 139762618615680 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0513 17:01:10.884018 139762618615680 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0513 17:01:10.931156 139762618615680 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/post_processing.py:581: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0513 17:01:11.360601 139762618615680 deprecation.py:323] From /content/models/research/object_detection/core/post_processing.py:581: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:295: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "W0513 17:01:11.843271 139762618615680 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:295: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:400: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0513 17:01:11.843608 139762618615680 deprecation.py:323] From /content/models/research/object_detection/exporter.py:400: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:432: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0513 17:01:11.847344 139762618615680 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:432: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:555: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W0513 17:01:11.847580 139762618615680 deprecation.py:323] From /content/models/research/object_detection/exporter.py:555: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W0513 17:01:11.848911 139762618615680 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "137 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/4.61m params)\n",
            "  BoxPredictor_0 (--/13.85k params)\n",
            "    BoxPredictor_0/BoxEncodingPredictor (--/6.92k params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x576x12, 6.91k/6.91k params)\n",
            "    BoxPredictor_0/ClassPredictor (--/6.92k params)\n",
            "      BoxPredictor_0/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_0/ClassPredictor/weights (1x1x576x12, 6.91k/6.91k params)\n",
            "  BoxPredictor_1 (--/61.49k params)\n",
            "    BoxPredictor_1/BoxEncodingPredictor (--/30.74k params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1280x24, 30.72k/30.72k params)\n",
            "    BoxPredictor_1/ClassPredictor (--/30.74k params)\n",
            "      BoxPredictor_1/ClassPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_1/ClassPredictor/weights (1x1x1280x24, 30.72k/30.72k params)\n",
            "  BoxPredictor_2 (--/24.62k params)\n",
            "    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "    BoxPredictor_2/ClassPredictor (--/12.31k params)\n",
            "      BoxPredictor_2/ClassPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_2/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "  BoxPredictor_3 (--/12.34k params)\n",
            "    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_3/ClassPredictor (--/6.17k params)\n",
            "      BoxPredictor_3/ClassPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_3/ClassPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "  BoxPredictor_4 (--/12.34k params)\n",
            "    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_4/ClassPredictor (--/6.17k params)\n",
            "      BoxPredictor_4/ClassPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_4/ClassPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "  BoxPredictor_5 (--/6.19k params)\n",
            "    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
            "    BoxPredictor_5/ClassPredictor (--/3.10k params)\n",
            "      BoxPredictor_5/ClassPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_5/ClassPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
            "  FeatureExtractor (--/4.48m params)\n",
            "    FeatureExtractor/MobilenetV2 (--/4.48m params)\n",
            "      FeatureExtractor/MobilenetV2/Conv (--/864 params)\n",
            "        FeatureExtractor/MobilenetV2/Conv/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/Conv/weights (3x3x3x32, 864/864 params)\n",
            "      FeatureExtractor/MobilenetV2/Conv_1 (--/409.60k params)\n",
            "        FeatureExtractor/MobilenetV2/Conv_1/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/Conv_1/weights (1x1x320x1280, 409.60k/409.60k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv (--/800 params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv/depthwise (--/288 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv/project (--/512 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/project/weights (1x1x32x16, 512/512 params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_1 (--/4.70k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise (--/864 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights (3x3x96x1, 864/864 params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_1/expand (--/1.54k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights (1x1x16x96, 1.54k/1.54k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_1/project (--/2.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights (1x1x96x24, 2.30k/2.30k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_10 (--/64.90k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_10/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_10/project (--/36.86k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights (1x1x384x96, 36.86k/36.86k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_11 (--/115.78k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise (--/5.18k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_11/expand (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_11/project (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_12 (--/115.78k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise (--/5.18k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_12/expand (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_12/project (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_13 (--/152.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise (--/5.18k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_13/expand (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_13/project (--/92.16k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_14 (--/315.84k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise (--/8.64k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_14/expand (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_14/project (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights (1x1x960x160, 153.60k/153.60k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_15 (--/315.84k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise (--/8.64k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_15/expand (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_15/project (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights (1x1x960x160, 153.60k/153.60k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_16 (--/469.44k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise (--/8.64k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_16/expand (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_16/project (--/307.20k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights (1x1x960x320, 307.20k/307.20k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_2 (--/8.21k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise (--/1.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_2/expand (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights (1x1x24x144, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_2/project (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights (1x1x144x24, 3.46k/3.46k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_3 (--/9.36k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise (--/1.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_3/expand (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights (1x1x24x144, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_3/project (--/4.61k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights (1x1x144x32, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_4 (--/14.02k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_4/expand (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_4/project (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights (1x1x192x32, 6.14k/6.14k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_5 (--/14.02k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_5/expand (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_5/project (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights (1x1x192x32, 6.14k/6.14k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_6 (--/20.16k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_6/expand (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_6/project (--/12.29k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_7 (--/52.61k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_7/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_7/project (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_8 (--/52.61k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_8/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_8/project (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_9 (--/52.61k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_9/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_9/project (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256 (--/327.68k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights (1x1x1280x256, 327.68k/327.68k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128 (--/65.54k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64 (--/16.38k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n",
            "\n",
            "======================End of Report==========================\n",
            "137 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/13.71k flops)\n",
            "  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n",
            "  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n",
            "  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n",
            "  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n",
            "  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n",
            "  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n",
            "  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:449: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0513 17:01:13.202100 139762618615680 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:449: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:359: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0513 17:01:14.224010 139762618615680 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:359: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-05-13 17:01:14.225451: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-05-13 17:01:14.248110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 17:01:14.248874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-13 17:01:14.249202: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-13 17:01:14.251072: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-13 17:01:14.252849: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-13 17:01:14.253200: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-13 17:01:14.266336: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-13 17:01:14.279169: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-13 17:01:14.298805: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-13 17:01:14.299051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 17:01:14.299951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 17:01:14.300787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-13 17:01:14.306741: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-05-13 17:01:14.306961: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x19aef40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-13 17:01:14.306996: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-05-13 17:01:14.356885: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 17:01:14.357743: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x19af100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-13 17:01:14.357780: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-05-13 17:01:14.357993: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 17:01:14.358740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-13 17:01:14.358823: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-13 17:01:14.358866: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-13 17:01:14.358910: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-13 17:01:14.358951: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-13 17:01:14.358988: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-13 17:01:14.359025: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-13 17:01:14.359063: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-13 17:01:14.359191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 17:01:14.359992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 17:01:14.360710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-13 17:01:14.360780: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-13 17:01:14.362337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-13 17:01:14.362370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-05-13 17:01:14.362388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-05-13 17:01:14.362584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 17:01:14.363373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 17:01:14.364087: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-05-13 17:01:14.364141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-1411\n",
            "I0513 17:01:14.366238 139762618615680 saver.py:1284] Restoring parameters from training/model.ckpt-1411\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0513 17:01:15.793481 139762618615680 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2020-05-13 17:01:16.480661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 17:01:16.481434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-13 17:01:16.481525: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-13 17:01:16.481591: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-13 17:01:16.481638: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-13 17:01:16.481680: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-13 17:01:16.481723: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-13 17:01:16.481763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-13 17:01:16.481803: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-13 17:01:16.481936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 17:01:16.482721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 17:01:16.483408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-13 17:01:16.483462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-13 17:01:16.483485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-05-13 17:01:16.483499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-05-13 17:01:16.483667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 17:01:16.484430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 17:01:16.485127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-1411\n",
            "I0513 17:01:16.486486 139762618615680 saver.py:1284] Restoring parameters from training/model.ckpt-1411\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0513 17:01:17.210172 139762618615680 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0513 17:01:17.210491 139762618615680 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 324 variables.\n",
            "I0513 17:01:17.650121 139762618615680 graph_util_impl.py:334] Froze 324 variables.\n",
            "INFO:tensorflow:Converted 324 variables to const ops.\n",
            "I0513 17:01:17.742293 139762618615680 graph_util_impl.py:394] Converted 324 variables to const ops.\n",
            "2020-05-13 17:01:17.882719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 17:01:17.883690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-13 17:01:17.883785: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-13 17:01:17.883831: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-13 17:01:17.883882: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-13 17:01:17.883926: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-13 17:01:17.883967: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-13 17:01:17.884006: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-13 17:01:17.884046: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-13 17:01:17.884187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 17:01:17.885077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 17:01:17.885813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-13 17:01:17.885866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-13 17:01:17.885890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-05-13 17:01:17.885905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-05-13 17:01:17.886059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 17:01:17.886939: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-13 17:01:17.887686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:323: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "W0513 17:01:18.557089 139762618615680 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:323: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:326: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0513 17:01:18.557683 139762618615680 deprecation.py:323] From /content/models/research/object_detection/exporter.py:326: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:332: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "W0513 17:01:18.558216 139762618615680 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:332: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:335: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "W0513 17:01:18.558443 139762618615680 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:335: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:340: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "W0513 17:01:18.558743 139762618615680 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:340: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:342: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
            "\n",
            "W0513 17:01:18.558939 139762618615680 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:342: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
            "\n",
            "INFO:tensorflow:No assets to save.\n",
            "I0513 17:01:18.559288 139762618615680 builder_impl.py:640] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0513 17:01:18.559424 139762618615680 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: ./fine_tuned_model/saved_model/saved_model.pb\n",
            "I0513 17:01:18.916064 139762618615680 builder_impl.py:425] SavedModel written to: ./fine_tuned_model/saved_model/saved_model.pb\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:223: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0513 17:01:18.943315 139762618615680 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:223: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "INFO:tensorflow:Writing pipeline config file to ./fine_tuned_model/pipeline.config\n",
            "I0513 17:01:18.943597 139762618615680 config_util.py:225] Writing pipeline config file to ./fine_tuned_model/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usgBZvkz0nqD",
        "colab_type": "code",
        "outputId": "82b4aab0-8d55-4daf-d57f-7d289a362492",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "!ls {output_directory}"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t\tmodel.ckpt.index  saved_model\n",
            "frozen_inference_graph.pb\tmodel.ckpt.meta\n",
            "model.ckpt.data-00000-of-00001\tpipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p09AOThWkaQv",
        "colab_type": "text"
      },
      "source": [
        "## Download the model `.pb` file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnDo1lonKgFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n",
        "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHqWkLBINYoI",
        "colab_type": "code",
        "outputId": "c1653095-a16e-4e8d-8e29-af101203d2c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls -alh {pb_fname}"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 19M May 13 17:01 /content/models/research/fine_tuned_model/frozen_inference_graph.pb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIqnjbWYsuQw",
        "colab_type": "text"
      },
      "source": [
        "### Option1 : upload the `.pb` file to your Google Drive\n",
        "Then download it from your Google Drive to local file system.\n",
        "\n",
        "During this step, you will be prompted to enter the token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAqyASIJqjae",
        "colab_type": "code",
        "outputId": "ad028c28-9324-4561-a466-47a0adda30e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fname = os.path.basename(pb_fname)\n",
        "# Create & upload a text file.\n",
        "uploaded = drive.CreateFile({'title': fname})\n",
        "uploaded.SetContentFile(pb_fname)\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1vHtzPMcxvPOkfvVKKcMTNaLDP6DPwFWh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FKFq8RXs6bs",
        "colab_type": "text"
      },
      "source": [
        "### Option2 :  Download the `.pb` file directly to your local file system\n",
        "This method may not be stable when downloading large files like the model `.pb` file. Try **option 1** instead if not working."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bP0iMMnnr77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(pb_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFyCeiBb9BbS",
        "colab_type": "text"
      },
      "source": [
        "### Download the `label_map.pbtxt` file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1TbL6Ox8q6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(label_map_pbtxt_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUmAo9foa1xq",
        "colab_type": "text"
      },
      "source": [
        "### Download the modified pipline file\n",
        "If you plan to use OpenVINO toolkit to convert the `.pb` file to inference faster on Intel's hardware (CPU/GPU, Movidius, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pql2QpemazE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(pipeline_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1AgBj1l0v_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !tar cfz fine_tuned_model.tar.gz fine_tuned_model\n",
        "# from google.colab import files\n",
        "# files.download('fine_tuned_model.tar.gz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz1gX19GlVW7",
        "colab_type": "text"
      },
      "source": [
        "## Run inference test\n",
        "Test with images in repository `object_detection_demo/test` directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzj9A4e5mj5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = pb_fname\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = label_map_pbtxt_fname\n",
        "\n",
        "# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n",
        "PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"test\")\n",
        "\n",
        "assert os.path.isfile(pb_fname)\n",
        "assert os.path.isfile(PATH_TO_LABELS)\n",
        "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n",
        "assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
        "print(TEST_IMAGE_PATHS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG5YUMdg1Po7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/models/research/object_detection\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            # Get handles to input and output tensors\n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {\n",
        "                output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in [\n",
        "                'num_detections', 'detection_boxes', 'detection_scores',\n",
        "                'detection_classes', 'detection_masks'\n",
        "            ]:\n",
        "                tensor_name = key + ':0'\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "                        tensor_name)\n",
        "            if 'detection_masks' in tensor_dict:\n",
        "                # The following processing is only for single image\n",
        "                detection_boxes = tf.squeeze(\n",
        "                    tensor_dict['detection_boxes'], [0])\n",
        "                detection_masks = tf.squeeze(\n",
        "                    tensor_dict['detection_masks'], [0])\n",
        "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "                real_num_detection = tf.cast(\n",
        "                    tensor_dict['num_detections'][0], tf.int32)\n",
        "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
        "                                           real_num_detection, -1])\n",
        "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
        "                                           real_num_detection, -1, -1])\n",
        "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "                detection_masks_reframed = tf.cast(\n",
        "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "                # Follow the convention by adding back the batch dimension\n",
        "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "                    detection_masks_reframed, 0)\n",
        "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "            # Run inference\n",
        "            output_dict = sess.run(tensor_dict,\n",
        "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "            output_dict['num_detections'] = int(\n",
        "                output_dict['num_detections'][0])\n",
        "            output_dict['detection_classes'] = output_dict[\n",
        "                'detection_classes'][0].astype(np.uint8)\n",
        "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "            if 'detection_masks' in output_dict:\n",
        "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "    return output_dict\n",
        "\n",
        "\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "    image = Image.open(image_path)\n",
        "    # the array based representation of the image will be used later in order to prepare the\n",
        "    # result image with boxes and labels on it.\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Actual detection.\n",
        "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "    # Visualization of the results of a detection.\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        output_dict['detection_boxes'],\n",
        "        output_dict['detection_classes'],\n",
        "        output_dict['detection_scores'],\n",
        "        category_index,\n",
        "        instance_masks=output_dict.get('detection_masks'),\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=8)\n",
        "    plt.figure(figsize=IMAGE_SIZE)\n",
        "    plt.imshow(image_np)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GStNeHWPkTcN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}